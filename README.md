# FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista


<a href= "https://www.fiap.com.br/"><img width="2385" height="642" alt="logo-fiap" src="https://github.com/user-attachments/assets/62285a6c-34fe-4206-8a85-7ad584c6908b" alt="FIAP - Faculdade de InformÃ¡tica e AdmnistraÃ§Ã£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>


# ğŸ“Š Fase 4 â€“ 1TIAOS â€“ CapÃ­tulo 3

## **(IR ALÃ‰M) Implementando Algoritmos de Machine Learning com Scikit-learn**

### ğŸ‘¨â€ğŸ’» Aluno

* [**Silvio Prestes Guerreiro Junior**](https://www.linkedin.com/in/silvio-guerreiro-junior/)
* **MatrÃ­cula:** RM567958
* **Grupo 25**

### ğŸ‘©â€ğŸ« Professores

* **Tutor(a):** Sabrina Otoni
* **Coordenador(a):** AndrÃ© Godoi Chiovato

# Projeto Seeds â€“ ClassificaÃ§Ã£o AutomÃ¡tica de GrÃ£os de Trigo

Este repositÃ³rio implementa a atividade **â€œDa Terra ao CÃ³digo: Automatizando a ClassificaÃ§Ã£o de GrÃ£os com Machine Learningâ€** da FIAP (Fase 4 â€“ CapÃ­tulo 3, IR ALÃ‰M).

O objetivo Ã© aplicar a metodologia **CRISPâ€‘DM** para desenvolver um modelo de aprendizado de mÃ¡quina capaz de **classificar automaticamente grÃ£os de trigo** em trÃªs variedades (Kama, Rosa e Canadian) a partir de suas caracterÃ­sticas fÃ­sicas, substituindo (ou complementando) a triagem manual feita por especialistas.

---

## ğŸ§­ Ãndice

- [Contexto do Problema](#-contexto-do-problema)
- [Dataset Utilizado](#-dataset-utilizado)
- [Metodologia e OrganizaÃ§Ã£o do Notebook](#-metodologia-e-organizaÃ§Ã£o-do-notebook)
- [Modelos de Machine Learning](#-modelos-de-machine-learning)
- [ConclusÃµes e RelatÃ³rio Executivo](#-conclusÃµes-e-relatÃ³rio-executivo)
- [Estrutura de Pastas](#-estrutura-de-pastas)
- [Como Executar o CÃ³digo](#-como-executar-o-cÃ³digo)
- [DependÃªncias e Tecnologias](#-dependÃªncias-e-tecnologias)
- [HistÃ³rico de LanÃ§amentos](#-histÃ³rico-de-lanÃ§amentos)
- [LicenÃ§a](#-licenÃ§a)
- [Autor](#-autor)

---

## ğŸŒ¾ Contexto do Problema

Em cooperativas agrÃ­colas de pequeno porte, a classificaÃ§Ã£o dos grÃ£os de trigo costuma ser:

- manual  
- demorada  
- sujeita a erro humano  
- difÃ­cil de padronizar e escalar

A proposta deste projeto Ã© **automatizar a classificaÃ§Ã£o de variedades de trigo** usando *Machine Learning*, apoiando a cooperativa fictÃ­cia **Farm Tech Solutions** na tomada de decisÃ£o: armazenagem, precificaÃ§Ã£o e atendimento a especificaÃ§Ãµes de clientes.

---

## ğŸ“Š Dataset Utilizado

O projeto utiliza o **Seeds Dataset** (UCI Machine Learning Repository), disponibilizado neste repositÃ³rio como `seeds_dataset.txt`. :contentReference[oaicite:1]{index=1}  

CaracterÃ­sticas:

- **210 amostras** de grÃ£os de trigo  
- **3 classes (variedades)**:
  - 1 â€“ Kama  
  - 2 â€“ Rosa  
  - 3 â€“ Canadian  
- **7 atributos numÃ©ricos (medidas geomÃ©tricas)**:
  1. Ãrea  
  2. PerÃ­metro  
  3. Compacidade  
  4. Comprimento do nÃºcleo  
  5. Largura do nÃºcleo  
  6. Assimetria  
  7. Comprimento do sulco do nÃºcleo (*groove_length*)

A Ãºltima coluna representa a **classe** (variedade do trigo).

---

## ğŸ”„ Metodologia e OrganizaÃ§Ã£o do Notebook

Todo o desenvolvimento estÃ¡ concentrado em:

- `Seeds_Notebook.ipynb` â€“ notebook principal com a soluÃ§Ã£o completa.

O notebook foi estruturado seguindo o **CRISPâ€‘DM**:

1. **Entendimento do NegÃ³cio**  
   - CenÃ¡rio da cooperativa Farm Tech Solutions  
   - Problemas da classificaÃ§Ã£o manual  
   - Objetivo de automaÃ§Ã£o e mÃ©tricas-alvo

2. **Entendimento e PreparaÃ§Ã£o dos Dados**  
   - Carregamento do `seeds_dataset.txt`  
   - RenomeaÃ§Ã£o das colunas  
   - EstatÃ­sticas descritivas (`describe()`)  
   - VerificaÃ§Ã£o de valores ausentes  
   - VisualizaÃ§Ãµes:
     - histogramas  
     - boxplots  
     - scatter plots  
     - matriz de correlaÃ§Ã£o  
   - DiscussÃ£o e aplicaÃ§Ã£o de **padronizaÃ§Ã£o** (`StandardScaler`) para modelos sensÃ­veis Ã  escala.

3. **Modelagem BÃ¡sica**  
   - DivisÃ£o treino/teste (70% / 30%)  
   - Treinamento inicial de:
     - **Kâ€‘Nearest Neighbors (KNN)**
     - **Support Vector Machine (SVM)**
     - **Random Forest**
   - AvaliaÃ§Ã£o com:
     - acurÃ¡cia  
     - precision, recall, F1â€‘score  
     - matriz de confusÃ£o para cada modelo

4. **OtimizaÃ§Ã£o de HiperparÃ¢metros**  
   - Uso de **GridSearchCV** para buscar a melhor configuraÃ§Ã£o de hiperparÃ¢metros  
   - Re-treino do modelo campeÃ£o com os parÃ¢metros otimizados  
   - ReavaliaÃ§Ã£o em teste

5. **Modelagem AvanÃ§ada**  
   - CriaÃ§Ã£o de **pipelines** (prÃ©-processamento + modelo)  
   - **ValidaÃ§Ã£o cruzada (5-fold)** para comparaÃ§Ã£o robusta entre algoritmos  
   - AplicaÃ§Ã£o de **PCA** para visualizaÃ§Ã£o em 2D da separaÃ§Ã£o entre classes

6. **ConclusÃµes e RelatÃ³rio Executivo**  
   - SÃ­ntese dos resultados tÃ©cnicos  
   - InterpretaÃ§Ã£o em linguagem de negÃ³cio  
   - RecomendaÃ§Ãµes prÃ¡ticas para a cooperativa

---

## ğŸ¤– Modelos de Machine Learning

TrÃªs algoritmos supervisionados de classificaÃ§Ã£o foram treinados e comparados:

- **KNN (K-Nearest Neighbors)**  
  Classifica um grÃ£o pela maioria dos vizinhos mais prÃ³ximos no espaÃ§o de atributos.

- **SVM (Support Vector Machine)**  
  Busca hiperplanos de decisÃ£o que maximizam a margem entre as classes.

- **Random Forest**  
  Conjunto de Ã¡rvores de decisÃ£o que captura relaÃ§Ãµes nÃ£o lineares e permite medir a importÃ¢ncia das features.

Todos os modelos foram avaliados com:

- AcurÃ¡cia  
- Precision, Recall e F1â€‘score (mÃ©dias ponderadas)  
- Matrizes de confusÃ£o  
- ValidaÃ§Ã£o cruzada (5-fold) com pipelines

---

## ğŸ“ˆ ConclusÃµes e RelatÃ³rio Executivo

### 1. SÃ­ntese do Experimento

- **Problema:** automatizar a classificaÃ§Ã£o de grÃ£os de trigo para reduzir esforÃ§o humano e padronizar decisÃµes.  
- **Dados:** 210 amostras, 7 atributos geomÃ©tricos, 3 variedades (Kama, Rosa, Canadian).  
- **Abordagem:** CRISPâ€‘DM, com forte foco em EDA, comparaÃ§Ã£o de algoritmos e otimizaÃ§Ã£o.  
- **Modelos testados:** KNN, SVM e Random Forest.  
- **AvaliaÃ§Ã£o:** conjunto de teste separado (30% do dataset) + validaÃ§Ã£o cruzada (5-fold) com pipelines.

### 2. Desempenho dos Modelos

ApÃ³s a fase de validaÃ§Ã£o e otimizaÃ§Ã£o:

- ğŸ¥‡ **Modelo CampeÃ£o: SVM (Support Vector Machine)**  
  - **AcurÃ¡cia mÃ©dia em validaÃ§Ã£o cruzada:** ~**93,20%**  
  - **AcurÃ¡cia no conjunto de teste (dados inÃ©ditos):** ~**87,30%**

Esses resultados indicam um modelo:

- estÃ¡vel (boa performance em diferentes folds),  
- com boa capacidade de generalizaÃ§Ã£o,  
- adequado para substituir parte da classificaÃ§Ã£o manual feita por especialistas.

### 3. Comportamento por Variedade (Matriz de ConfusÃ£o)

No conjunto de teste (63 amostras), a matriz de confusÃ£o do SVM mostra:

- **Canadian (Classe 3):**  
  - ~**95% de acerto** (20/21 amostras corretamente classificadas)  
  - Variedade mais fÃ¡cil para o modelo.

- **Rosa (Classe 2):**  
  - ~**90% de acerto** (19/21 amostras)  
  - Modelo bastante confiÃ¡vel.

- **Kama (Classe 1):**  
  - ~**76% de acerto** (16/21 amostras)  
  - Maior fonte de erro: parte dos grÃ£os Kama Ã© confundida com Rosa ou Canadian.

> **Insight:** a variedade **Kama** tem caracterÃ­sticas geomÃ©tricas mais â€œintermediÃ¡riasâ€ ou maior variabilidade interna, o que torna sua classificaÃ§Ã£o mais difÃ­cil e exige atenÃ§Ã£o especial em produÃ§Ã£o.

### 4. Insights sobre as CaracterÃ­sticas

A anÃ¡lise de importÃ¢ncia das features (Random Forest) e os grÃ¡ficos derivados do PCA indicam:

- **Atributos mais importantes:**
  - **Comprimento do Sulco do NÃºcleo (*groove_length*)**  
  - **PerÃ­metro**  
  - **Ãrea**
- **Atributos menos relevantes:**
  - **Compacidade**  
  - **Assimetria**

Implica em termos de negÃ³cio e engenharia:

- Sensores/cÃ¢meras devem ser escolhidos e calibrados para medir com **alta precisÃ£o**:
  - o contorno do grÃ£o,  
  - a Ã¡rea projetada,  
  - e a geometria do sulco.

- Em cenÃ¡rios com limitaÃ§Ã£o de hardware, compacidade e assimetria podem ter prioridade menor.

### 5. AvaliaÃ§Ã£o de Viabilidade

**Pergunta central:**  
> â€œÃ‰ viÃ¡vel substituir, ao menos parcialmente, a classificaÃ§Ã£o manual por um modelo de IA confiÃ¡vel?â€

**Resposta:**  
âœ… **Sim, a automaÃ§Ã£o Ã© tecnicamente viÃ¡vel e recomendÃ¡vel.**

O modelo SVM:

- mantÃ©m acurÃ¡cia prÃ³xima a 90%;  
- reduz variabilidade entre avaliadores humanos;  
- Ã© rÃ¡pido o suficiente para operar em linhas de triagem em tempo quase real.

### 6. RecomendaÃ§Ãµes para a Farm Tech Solutions

1. **AutomaÃ§Ã£o Parcial Imediata**
   - Utilizar o modelo SVM como primeira etapa de decisÃ£o para todas as variedades.  
   - Encaminhar apenas casos de **baixa confianÃ§a** ou amostras classificadas como **Kama** para revisÃ£o manual.

2. **Investimento em Hardware**
   - Priorizar sensores de visÃ£o/cÃ¢meras que permitam extrair:
     - Ã¡rea,  
     - perÃ­metro,  
     - comprimento do sulco.  
   - Avaliar tradeâ€‘offs de custo versus resoluÃ§Ã£o necessÃ¡ria.

3. **Fluxo Operacional Sugerido**
   1. GrÃ£o passa por cÃ¢mera/sensor em esteira.  
   2. Imagem Ã© processada para extrair features geomÃ©tricas.  
   3. Features sÃ£o enviadas ao modelo SVM.  
   4. Modelo retorna:
      - classe prevista (Kama, Rosa, Canadian);  
      - score de confianÃ§a.  
   5. GrÃ£os com baixa confianÃ§a ou Kama sÃ£o rotulados para conferÃªncia manual.

---

## ğŸ“ Estrutura de Pastas

```text
FASE4_ATIVIDADE_CAP3/
â”‚
â”œâ”€ .venv/                  # Ambiente virtual Python 
â”œâ”€ requirements.txt        # Lista de dependÃªncias do projeto
â”œâ”€ seeds_dataset.txt       # Seeds Dataset (dados de entrada)
â””â”€ Seeds_Notebook.ipynb    # Notebook Jupyter com toda a anÃ¡lise e modelagem
````

---

## âš™ï¸ Como Executar o CÃ³digo

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/SEU-USUARIO/FASE4_ATIVIDADE_CAP3.git
cd FASE4_ATIVIDADE_CAP3
```

### 2. (Opcional, mas recomendado) Criar e ativar o ambiente virtual

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux / macOS
source .venv/bin/activate
```

### 3. Instalar as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Abrir o notebook

Usando Jupyter:

```bash
jupyter notebook Seeds_Notebook.ipynb
```

Ou diretamente pelo **VS Code**, com a extensÃ£o *Jupyter* instalada, abrindo o arquivo `Seeds_Notebook.ipynb` e executando as cÃ©lulas na ordem.

---

## ğŸ§© DependÃªncias e Tecnologias

Principais ferramentas e bibliotecas utilizadas (versÃµes especificadas em `requirements.txt`):

* **Python 3.x**
* **Jupyter / VS Code (Jupyter extension)**
* `pandas`, `numpy` â€“ manipulaÃ§Ã£o e anÃ¡lise de dados
* `scikit-learn` â€“ modelos de Machine Learning (KNN, SVM, Random Forest, GridSearchCV, pipelines, validaÃ§Ã£o cruzada) 
* `matplotlib`, `seaborn` â€“ visualizaÃ§Ã£o de dados
* Outras libs de apoio descritas em `requirements.txt` (ipykernel, scipy etc.). 

---

## ğŸ“ HistÃ³rico de LanÃ§amentos

* **v1.0.0 â€“ Entrega FIAP (CapÃ­tulo 3 â€“ IR ALÃ‰M)**

  * Notebook `Seeds_Notebook.ipynb` finalizado
  * EDA completa (grÃ¡ficos, estatÃ­sticas, correlaÃ§Ã£o)
  * ImplementaÃ§Ã£o de KNN, SVM e Random Forest
  * ValidaÃ§Ã£o cruzada + GridSearchCV
  * ConclusÃµes e relatÃ³rio executivo


---

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido exclusivamente para fins acadÃªmicos â€“ FIAP. Qualquer uso, modificaÃ§Ã£o ou redistribuiÃ§Ã£o deve seguir as diretrizes institucionais e de propriedade intelectual aplicÃ¡veis.

---

```
